{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   InvoiceNo    541909 non-null  object \n",
      " 1   StockCode    541909 non-null  object \n",
      " 2   Description  540455 non-null  object \n",
      " 3   Quantity     541909 non-null  int64  \n",
      " 4   UnitPrice    541909 non-null  float64\n",
      " 5   CustomerID   406829 non-null  float64\n",
      " 6   Country      541909 non-null  object \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 28.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import time\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from utils import *\n",
    "from model import Recommendation\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def preprocessing(data):\n",
    "    print('Number of rows removed:')\n",
    "    print('Quantity:\\t{:>6} row(s)'.format((data.Quantity<0).sum()))\n",
    "    data = data[filter_negative(data.Quantity)]\n",
    "    \n",
    "    print('Unit Price:\\t{:>6} row(s)'.format((data.UnitPrice<0).sum()))\n",
    "    data = data[filter_negative(data.UnitPrice)]\n",
    "    \n",
    "    print('Customer ID:\\t{:>6} row(s)'.format(data.CustomerID.isnull().sum()))\n",
    "    data = data[data.CustomerID.notnull()]\n",
    "    \n",
    "    print('\\nData final shape: ', data.shape)\n",
    "    return data\n",
    "    \n",
    "\n",
    "def prepare_dataset(data, embedidx_item):\n",
    "    train = set()\n",
    "    invoices = set(data.InvoiceNo)\n",
    "    for invoice in invoices:\n",
    "        data_ = data[data.InvoiceNo == invoice]\n",
    "        items_ = list(set(data_.EmbeddingID))\n",
    "        if len(items_) > 1:\n",
    "            for i in range(len(items_)-1):\n",
    "                for j in range(i+1, len(items_)):\n",
    "                    if (items_[i], items_[j]) not in train:\n",
    "                        train.add((items_[i], items_[j], 1))\n",
    "    \n",
    "    # Create negative training data\n",
    "    for _ in range(len(train)):\n",
    "        x, y = random.sample(range(len(embedidx_item)), 2)\n",
    "        if (x, y, 1) not in train:\n",
    "            train.add((x, y, -1))\n",
    "            \n",
    "    return torch.tensor(list(train))\n",
    "\n",
    "\n",
    "def generate_recommendation(code, matrix):\n",
    "    item = item_embedidx[code]  # Take item embedding matrix\n",
    "    \n",
    "    #Calculate score\n",
    "    score = torch.mm(matrix, matrix[item].unsqueeze(1)).view(-1)\n",
    "    idx_sort = torch.argsort(score, descending=True)\n",
    "    \n",
    "    print('Top 5 frequently bought together with \"{}\": '.format(items[code]))\n",
    "    for i in idx_sort[1:6].numpy():\n",
    "        item_code = embedidx_item[i]\n",
    "        print('Item code: {}\\t Similarity: {:4f}\\t Name: {}'.format(item_code,\n",
    "                                                                    score[i].numpy(),\n",
    "                                                                    items[item_code]\n",
    "                                                                   ))\n",
    "\n",
    "\n",
    "\n",
    "data = read_data('data.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PREPROCESSING DATA\n",
    "Based on information generated from `DataFrame.info()`:\n",
    "* `InvoiceNo`: no filter applied</i>\n",
    "* `StockCode`: no filter applied\n",
    "* `Description`: no filter applied even when there are lots of null\n",
    "* `Quantity`: filter negative value\n",
    "* `UnitPrice`: filter negative value\n",
    "* `CustomerID`: filter null value\n",
    "* `Country`: no filter applied\n",
    "* Add a new column `Value` = `Quantity` * `UnitPrice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows removed:\n",
      "Quantity:\t 10624 row(s)\n",
      "Unit Price:\t     2 row(s)\n",
      "Customer ID:\t132220 row(s)\n",
      "\n",
      "Data final shape:  (397884, 7)\n",
      "            Quantity      UnitPrice     CustomerID          Value\n",
      "count  397884.000000  397884.000000  397884.000000  397884.000000\n",
      "mean       12.988238       3.116488   15294.423453      22.397000\n",
      "std       179.331775      22.097877    1713.141560     309.071041\n",
      "min         1.000000       0.001000   12346.000000       0.001000\n",
      "25%         2.000000       1.250000   13969.000000       4.680000\n",
      "50%         6.000000       1.950000   15159.000000      11.800000\n",
      "75%        12.000000       3.750000   16795.000000      19.800000\n",
      "max     80995.000000    8142.750000   18287.000000  168469.600000\n",
      "\n",
      "\n",
      "New DataFrame:\n",
      "    InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "   UnitPrice  CustomerID         Country  Value  \n",
      "0       2.55     17850.0  United Kingdom  15.30  \n",
      "1       3.39     17850.0  United Kingdom  20.34  \n",
      "2       2.75     17850.0  United Kingdom  22.00  \n",
      "3       3.39     17850.0  United Kingdom  20.34  \n",
      "4       3.39     17850.0  United Kingdom  20.34  \n"
     ]
    }
   ],
   "source": [
    "data_filtered = preprocessing(data)   \n",
    "data_filtered['Value'] = data_filtered.Quantity * data_filtered.UnitPrice\n",
    "print(data_filtered.describe())\n",
    "print('\\n\\nNew DataFrame:\\n ',data_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3665, 3877)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = dict(data_filtered[['StockCode', 'Description']].values)\n",
    "item_indexes = dict(data_filtered[['Description', 'StockCode']].values)\n",
    "len(items), len(item_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the `items` and `item_indexes` have different shape so an item code can have multiple descriptions. Assume that the data file was sorted by order date, the higher number of row the updated desciption of item code. We gonna use `items` dictionary for references\n",
    "\n",
    "> For visualization. I don't recommend using Python. Other BI tools such as Tableau, Qlik or PowerBI are much more better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RECOMMENDATION SYSTEM\n",
    "The training dataset is created base on which items usually be bought with an item. I create an embedding matrix, as the result, the closer item vectors are the similar they are. First thing is creating some `dict` to map between embedding matrix index, item code & item name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedidx_item = dict(enumerate(items.keys())) #Embedding reference when put it into model\n",
    "item_embedidx = dict(list(zip(embedidx_item.values(), embedidx_item.keys())))\n",
    "\n",
    "# Add Embedding Id for item\n",
    "data_filtered['EmbeddingID'] = data_filtered.StockCode.apply(lambda x: item_embedidx[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A training data looks like `(x1, x2, y)` where:\n",
    "* `x1` is an embedding index of an item\n",
    "* `x2` is another embedding index of an time that being bought in the same `InvoiceNo`\n",
    "* y = 1 when `x1` is bought with `x2`, otherwise y = -1 with random 2 items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 , loss = 79.55053985118866, time = 8.842999935150146\n",
      "Epoch = 1 , loss = 79.39837300777435, time = 8.833001852035522\n",
      "Epoch = 2 , loss = 79.24727785587311, time = 8.861000299453735\n",
      "Epoch = 3 , loss = 79.07064807415009, time = 8.61099362373352\n",
      "Epoch = 4 , loss = 78.90417742729187, time = 8.803002119064331\n",
      "Epoch = 5 , loss = 78.69434082508087, time = 8.807997465133667\n",
      "Epoch = 6 , loss = 78.46229928731918, time = 8.936001300811768\n",
      "Epoch = 7 , loss = 78.19204539060593, time = 8.698003768920898\n",
      "Epoch = 8 , loss = 77.87197816371918, time = 8.739996433258057\n",
      "Epoch = 9 , loss = 77.48854184150696, time = 8.927002191543579\n"
     ]
    }
   ],
   "source": [
    "# Generate training dataset\n",
    "tensors = prepare_dataset(data_filtered.loc[:50000], embedidx_item)\n",
    "data_loader = DataLoader(TensorDataset(tensors[:,:2], tensors[:,2].type(torch.float).unsqueeze(1)), \n",
    "                         batch_size=10000,\n",
    "                         shuffle=True\n",
    "                        )\n",
    "\n",
    "\n",
    "# Load model and train\n",
    "model = Recommendation(nums=len(embedidx_item), dim=50) # Please refer to model.py for details\n",
    "model.to(DEVICE)\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    s = time.time()\n",
    "    for x, y in data_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(x,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print('Epoch = {:<2}, loss = {:<6}, time = {:<5}'.format(epoch, total_loss, time.time()-s))\n",
    "\n",
    "\n",
    "# Export embedding layers from model\n",
    "item_embedding = model.embed.weight.data.detach().cpu()\n",
    "item_embedding = F.normalize(item_embedding, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 frequently bought together with \"OCEAN STRIPE HAMMOCK \": \n",
      "Item code: 22301\t Similarity: 0.494373\t Name: COFFEE MUG CAT + BIRD DESIGN\n",
      "Item code: 21286\t Similarity: 0.479872\t Name: RETROSPOT CANDLE  LARGE\n",
      "Item code: 85123A\t Similarity: 0.463026\t Name: CREAM HANGING HEART T-LIGHT HOLDER\n",
      "Item code: 72816\t Similarity: 0.440908\t Name: SET/3 CHRISTMAS DECOUPAGE CANDLES\n",
      "Item code: 84877B\t Similarity: 0.428294\t Name: GREEN ROUND COMPACT MIRROR\n"
     ]
    }
   ],
   "source": [
    "ITEM_CODE = '84795C'\n",
    "generate_recommendation(ITEM_CODE, item_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ML Pipeline\n",
    "At the end of day `t`, the database will generate a data file of that day with format `data_yyyymmdd.csv` to keep track. Then the `model` at date `t` take preprocessed data from csv file to update parameters, also save model weights as `model_yyyymmdd.h5`. It is necessary to store model weights after each update to make backups if there is any thing wrong.\n",
    "Pipeline: <img src=\"./pipline.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
